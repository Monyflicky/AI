{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVtTucC1ektu",
        "outputId": "39adb8dd-5fa3-4619-d012-9d46059c5fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'I would like to buy a mozzarella pizza',\n",
              " 'labels': ['order a pizza', 'inform my address', 'choose drinks'],\n",
              " 'scores': [0.9591404795646667, 0.03356859087944031, 0.007290858309715986]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# !pip install transformers\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "sequence_to_classify = \"I would like to buy a mozzarella pizza\"\n",
        "\n",
        "candidate_labels = [\"choose drinks\", \"order a pizza\", \"inform my address\"]\n",
        "\n",
        "generator(sequence_to_classify, candidate_labels)\n",
        "\n"
      ]
    }
  ]
}